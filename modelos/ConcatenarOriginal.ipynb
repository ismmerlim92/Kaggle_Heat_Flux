{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "import scipy.io\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pressure [MPa]</th>\n",
       "      <th>mass_flux [kg/m2-s]</th>\n",
       "      <th>x_e_out [-]</th>\n",
       "      <th>D_e [mm]</th>\n",
       "      <th>D_h [mm]</th>\n",
       "      <th>length [mm]</th>\n",
       "      <th>chf_exp [MW/m2]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>7.00</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.8</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>tube</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6049.0</td>\n",
       "      <td>-0.0416</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>762.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.79</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beus</td>\n",
       "      <td>annulus</td>\n",
       "      <td>13.79</td>\n",
       "      <td>3679.0</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>5.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2134.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>13.79</td>\n",
       "      <td>686.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>457.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.24</td>\n",
       "      <td>3648.0</td>\n",
       "      <td>-0.0711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>696.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Thompson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.89</td>\n",
       "      <td>549.0</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Peskov</td>\n",
       "      <td>tube</td>\n",
       "      <td>18.00</td>\n",
       "      <td>750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tube</td>\n",
       "      <td>12.07</td>\n",
       "      <td>4042.0</td>\n",
       "      <td>-0.0536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Peskov</td>\n",
       "      <td>tube</td>\n",
       "      <td>12.00</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    author geometry  pressure [MPa]  mass_flux [kg/m2-s]  x_e_out [-]  \\\n",
       "0   0  Thompson     tube            7.00               3770.0       0.1754   \n",
       "1   1  Thompson     tube             NaN               6049.0      -0.0416   \n",
       "2   2  Thompson      NaN           13.79               2034.0       0.0335   \n",
       "3   3      Beus  annulus           13.79               3679.0      -0.0279   \n",
       "4   4       NaN     tube           13.79                686.0          NaN   \n",
       "5   5       NaN      NaN           17.24               3648.0      -0.0711   \n",
       "6   6  Thompson      NaN            6.89                549.0       0.1203   \n",
       "7   7    Peskov     tube           18.00                750.0          NaN   \n",
       "8   8       NaN     tube           12.07               4042.0      -0.0536   \n",
       "9   9    Peskov     tube           12.00               1617.0       0.1228   \n",
       "\n",
       "   D_e [mm]  D_h [mm]  length [mm]  chf_exp [MW/m2]  \n",
       "0       NaN      10.8        432.0              3.6  \n",
       "1      10.3      10.3        762.0              6.2  \n",
       "2       7.7       7.7        457.0              2.5  \n",
       "3       5.6      15.2       2134.0              3.0  \n",
       "4      11.1      11.1        457.0              2.8  \n",
       "5       NaN       1.9        696.0              3.6  \n",
       "6      12.8      12.8       1930.0              2.6  \n",
       "7      10.0      10.0       1650.0              2.2  \n",
       "8       NaN       NaN        152.0              5.6  \n",
       "9      10.0      10.0        520.0              2.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un diccionario de mapeo para los valores conocidos de \"author\" y \"geometry\"\n",
    "mapeo_geometry = {\n",
    "    'Thompson': 'tube',\n",
    "    'Peskov': 'tube',\n",
    "    'Weatherhead': 'tube',\n",
    "    'Inasaka': 'tube',\n",
    "    'Williams': 'tube',\n",
    "    'Beus': 'annulus',\n",
    "    'Janssen': 'annulus',\n",
    "    'Mortimore': 'annulus',\n",
    "    'Richenderfer': 'plate',\n",
    "    'Kossolapov': 'plate'\n",
    "}\n",
    "\n",
    "# Rellenar los valores nulos en \"geometry\" utilizando el diccionario de mapeo\n",
    "df['geometry'] = df['geometry'].fillna(df['author'].map(mapeo_geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenar los nulos en \"length [mm]\" con 10.0 cuando la columna \"geometry\" es \"plate\"\n",
    "df.loc[df['geometry'] == 'plate', 'length [mm]'] = df.loc[df['geometry'] == 'plate', 'length [mm]'].fillna(10.0)\n",
    "\n",
    "# Llenar los nulos en \"D_e [mm]\" con 15.0 cuando la columna \"geometry\" es \"plate\"\n",
    "df.loc[df['geometry'] == 'plate', 'D_e [mm]'] = df.loc[df['geometry'] == 'plate', 'D_e [mm]'].fillna(15.0)\n",
    "\n",
    "# Llenar los nulos en \"D_h [mm]\" con 120.0 cuando la columna \"geometry\" es \"plate\"\n",
    "df.loc[df['geometry'] == 'plate', 'D_h [mm]'] = df.loc[df['geometry'] == 'plate', 'D_h [mm]'].fillna(120.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          author geometry      0\n",
      "0           Beus  annulus   1575\n",
      "1           Beus     tube     29\n",
      "2        Inasaka    plate      1\n",
      "3        Inasaka     tube     45\n",
      "4        Janssen  annulus   2684\n",
      "5        Janssen    plate      1\n",
      "6        Janssen     tube     31\n",
      "7     Kossolapov  annulus      1\n",
      "8     Kossolapov    plate     97\n",
      "9     Kossolapov     tube      3\n",
      "10     Mortimore  annulus    189\n",
      "11     Mortimore    plate      2\n",
      "12     Mortimore     tube      6\n",
      "13        Peskov  annulus      1\n",
      "14        Peskov    plate      3\n",
      "15        Peskov     tube   1080\n",
      "16  Richenderfer  annulus      6\n",
      "17  Richenderfer    plate    504\n",
      "18  Richenderfer     tube     35\n",
      "19      Thompson  annulus      9\n",
      "20      Thompson    plate     11\n",
      "21      Thompson     tube  17376\n",
      "22   Weatherhead  annulus      1\n",
      "23   Weatherhead     tube   2039\n",
      "24      Williams  annulus      1\n",
      "25      Williams    plate      1\n",
      "26      Williams     tube    889\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por \"author\" y \"geometry\" y obtener los valores únicos\n",
    "unique_values = df.groupby(['author', 'geometry']).size().reset_index()\n",
    "\n",
    "# Mostrar los valores únicos para cada grupo\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las filas con valores nulos en la columna 'x_e_out'\n",
    "df_nulos = df[df['x_e_out [-]'].isnull()]\n",
    "\n",
    "# Crear un nuevo DataFrame con las filas que contienen valores nulos en 'x_e_out'\n",
    "nuevos_datos = df_nulos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['x_e_out [-]'])\n",
    "\n",
    "# Imprimir el DataFrame original sin las filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry'] = df['geometry'].fillna('tube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un diccionario de mapeo para los valores conocidos de \"author\" y \"geometry\"\n",
    "mapeo_geometry = {\n",
    "    'Thompson': 'tube',\n",
    "    'Peskov': 'tube',\n",
    "    'Weatherhead': 'tube',\n",
    "    'Inasaka': 'tube',\n",
    "    'Williams': 'tube',\n",
    "    'Beus': 'annulus',\n",
    "    'Janssen': 'annulus',\n",
    "    'Mortimore': 'annulus',\n",
    "    'Richenderfer': 'plate',\n",
    "    'Kossolapov': 'plate'\n",
    "}\n",
    "\n",
    "# Rellenar los valores nulos en \"geometry\" utilizando el diccionario de mapeo\n",
    "nuevos_datos['geometry'] = nuevos_datos['geometry'].fillna(nuevos_datos['author'].map(mapeo_geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos['geometry'] = nuevos_datos['geometry'].fillna('tube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mRichenderfer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mannulus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mannulus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mBeus\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m nuevos_datos\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtube\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nuevos_datos\u001b[39m.\u001b[39;49mloc[df[\u001b[39m'\u001b[39;49m\u001b[39mgeometry\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtube\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mauthor\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mThompson\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m nuevos_datos\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nuevos_datos\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mRichenderfer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m nuevos_datos\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mannulus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nuevos_datos\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mgeometry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mannulus\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mBeus\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1292\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_slice_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1291\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getbool_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1293\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1294\u001b[0m \n\u001b[0;32m   1295\u001b[0m     \u001b[39m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1091\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1088\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getbool_axis\u001b[39m(\u001b[39mself\u001b[39m, key, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1089\u001b[0m     \u001b[39m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1091\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1092\u001b[0m     inds \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1093\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:2552\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2550\u001b[0m indexer \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m indexer:\n\u001b[1;32m-> 2552\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2553\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnalignable boolean Series provided as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2554\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindexer (index of the boolean Series and of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2555\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe indexed object do not match).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2556\u001b[0m     )\n\u001b[0;32m   2558\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   2560\u001b[0m \u001b[39m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "df.loc[df['geometry'] == 'tube', 'author'] = df.loc[df['geometry'] == 'tube', 'author'].fillna('Thompson')\n",
    "df.loc[df['geometry'] == 'plate', 'author'] = df.loc[df['geometry'] == 'plate', 'author'].fillna('Richenderfer')\n",
    "df.loc[df['geometry'] == 'annulus', 'author'] = df.loc[df['geometry'] == 'annulus', 'author'].fillna('Beus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_datos.loc[nuevos_datos['geometry'] == 'tube', 'author'] = nuevos_datos.loc[nuevos_datos['geometry'] == 'tube', 'author'].fillna('Thompson')\n",
    "nuevos_datos.loc[nuevos_datos['geometry'] == 'plate', 'author'] = nuevos_datos.loc[nuevos_datos['geometry'] == 'plate', 'author'].fillna('Richenderfer')\n",
    "nuevos_datos.loc[nuevos_datos['geometry'] == 'annulus', 'author'] = nuevos_datos.loc[nuevos_datos['geometry'] == 'annulus', 'author'].fillna('Beus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar codificación one-hot a la columna \"author\"\n",
    "df = pd.get_dummies(df, columns=['author'], prefix=['author'])\n",
    "\n",
    "# Aplicar codificación one-hot a la columna \"geometry\"\n",
    "df = pd.get_dummies(df, columns=['geometry'], prefix=['geometry'])\n",
    "\n",
    "# Aplicar codificación one-hot a la columna \"author\"\n",
    "nuevos_datos = pd.get_dummies(nuevos_datos, columns=['author'], prefix=['author'])\n",
    "\n",
    "# Aplicar codificación one-hot a la columna \"geometry\"\n",
    "nuevos_datos = pd.get_dummies(nuevos_datos, columns=['geometry'], prefix=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en X e y\n",
    "X = df.drop(['x_e_out [-]', 'id'], axis=1)  # Todas las columnas excepto 'x_e_out'\n",
    "y = df['x_e_out [-]']  # Solo la columna 'x_e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características (X) y la columna objetivo (y)\n",
    "X_nuevos_datos = nuevos_datos.drop(columns=[\"x_e_out [-]\"])\n",
    "y_nuevos_datos = nuevos_datos[\"x_e_out [-]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(columns={'pressure [MPa]': 'pressure', 'mass_flux [kg/m2-s]': 'mass_flux', \n",
    "                    'D_e [mm]': 'D_e', 'D_h [mm]': 'D_h', 'length [mm]': 'length'\n",
    "                    , 'chf_exp [MW/m2]': 'chf_exp'}, inplace=True)\n",
    "\n",
    "y.name = 'x_e_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nuevos_datos.rename(columns={'pressure [MPa]': 'pressure', 'mass_flux [kg/m2-s]': 'mass_flux', \n",
    "                    'D_e [mm]': 'D_e', 'D_h [mm]': 'D_h', 'length [mm]': 'length'\n",
    "                    , 'chf_exp [MW/m2]': 'chf_exp'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_additional = pd.read_csv('data/Data_CHF_Zhao_2020_ATE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar codificación one-hot a la columna \"author\"\n",
    "df_additional = pd.get_dummies(df_additional, columns=['author'], prefix=['author'])\n",
    "\n",
    "# Aplicar codificación one-hot a la columna \"geometry\"\n",
    "df_additional = pd.get_dummies(df_additional, columns=['geometry'], prefix=['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en X e y\n",
    "X_additional = df_additional.drop(['x_e_out [-]', 'id'], axis=1)  # Todas las columnas excepto 'x_e_out'\n",
    "Y_additional = df_additional['x_e_out [-]']  # Solo la columna 'x_e_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_additional.rename(columns={'pressure [MPa]': 'pressure', 'mass_flux [kg/m2-s]': 'mass_flux', \n",
    "                    'D_e [mm]': 'D_e', 'D_h [mm]': 'D_h', 'length [mm]': 'length'\n",
    "                    , 'chf_exp [MW/m2]': 'chf_exp'}, inplace=True)\n",
    "\n",
    "Y_additional.name = 'x_e_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((X_train, X_additional), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((y_train, Y_additional), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m X_train\u001b[39m.\u001b[39;49minfo()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "# Paso 4: Concatenar X_additional y y_additional a X_train y y_train\n",
    "X_train = np.concatenate((X_train, X_additional), axis=0)\n",
    "y_train = np.concatenate((y_train, Y_additional), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar las características (X) y la columna objetivo (y)\n",
    "X_nuevos_datos = nuevos_datos.drop(columns=[\"x_e_out [-]\"])\n",
    "y_nuevos_datos = nuevos_datos[\"x_e_out [-]\"]\n",
    "\n",
    "# Imputar los valores nulos en las características (X)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_nuevos_datos_imputed = imputer.fit_transform(X_nuevos_datos)\n",
    "\n",
    "#Separar las características (X) y la columna objetivo (y)\n",
    "X_nuevos_datos = nuevos_datos.drop(columns=[\"x_e_out [-]\"])\n",
    "y_nuevos_datos = nuevos_datos[\"x_e_out [-]\"]\n",
    "\n",
    "\n",
    "# Convertir el resultado a DataFrame\n",
    "X_nuevos_datos_imputed = pd.DataFrame(X_nuevos_datos_imputed, columns=X_nuevos_datos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.07476652530144405\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "# Paso 4: Concatenar X_additional y y_additional a X_train y y_train\n",
    "X_train = np.concatenate((X_train, X_additional), axis=0)\n",
    "y_train = np.concatenate((y_train, Y_additional), axis=0)\n",
    "\n",
    "# Paso 5: Definir las transformaciones y el modelo\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "scaler = StandardScaler()\n",
    "model = XGBRegressor(colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.6)\n",
    "\n",
    "# Paso 6: Crear el pipeline\n",
    "xg_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Paso 7: Ajustar el pipeline a los datos de entrenamiento\n",
    "xg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Paso 8: Realizar predicciones en los datos de prueba\n",
    "y_pred = xg_pipeline.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcular el RMSE\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar las características (X) y la columna objetivo (y)\n",
    "X_nuevos_datos = nuevos_datos.drop(columns=[\"x_e_out [-]\"])\n",
    "y_nuevos_datos = nuevos_datos[\"x_e_out [-]\"]\n",
    "\n",
    "# Imputar los valores nulos en las características (X)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_nuevos_datos_imputed = imputer.fit_transform(X_nuevos_datos)\n",
    "\n",
    "# Convertir el resultado a DataFrame\n",
    "X_nuevos_datos_imputed = pd.DataFrame(X_nuevos_datos_imputed, columns=X_nuevos_datos.columns)\n",
    "\n",
    "# # Crear el objeto de regresión lineal\n",
    "# regression_model = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nuevos_datos_imputed = X_nuevos_datos_imputed.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Realizar predicciones en la columna objetivo (y) para los datos imputados\n",
    "y_pred1 = xg_pipeline.predict(X_nuevos_datos_imputed)\n",
    "\n",
    "# Combinar las predicciones con los datos originales\n",
    "nuevos_datos[\"x_e_out [-]\"] = y_pred1\n",
    "\n",
    "# Los datos ahora tienen las predicciones en la columna objetivo (y)\n",
    "\n",
    "# Guardar los datos en un archivo para la competición de Kaggle\n",
    "nuevos_datos.to_csv(\"nuevos_datos_con_predicciones2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Leer el archivo CSV\n",
    "prueba1 = pd.read_csv(\"nuevos_datos_con_predicciones2.csv\")\n",
    "\n",
    "# Mantener solo las columnas \"id\" y \"x_e_out [mm]\"\n",
    "columnas_deseadas = [\"id\", \"x_e_out [-]\"]\n",
    "prueba1 = prueba1[columnas_deseadas]\n",
    "\n",
    "# Guardar el DataFrame resultante en un nuevo archivo CSV\n",
    "prueba1.to_csv(\"nuevos_datos_con_predicciones_filtrado10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but IterativeImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but IterativeImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but IterativeImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but IterativeImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Random Forest): 0.07819002635166862\n",
      "RMSE (Gradient Boosting): 0.07666082924356261\n",
      "RMSE (AdaBoost): 0.09634552137702061\n",
      "RMSE (Extra Trees): 0.07992261175403133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Paso 5: Definir las transformaciones y los modelos\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "scaler = StandardScaler()\n",
    "rf_model = RandomForestRegressor(max_depth= 12, min_samples_leaf= 5, min_samples_split= 10, n_estimators= 100)\n",
    "gb_model = GradientBoostingRegressor(max_depth=5, n_estimators=100, learning_rate=0.1)\n",
    "ada_model = AdaBoostRegressor(n_estimators=100)\n",
    "et_model = ExtraTreesRegressor(min_samples_split=8, n_estimators= 400)\n",
    "\n",
    "# Paso 6: Crear los pipelines para Random Forest y Gradient Boosting\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', rf_model)\n",
    "])\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', gb_model)\n",
    "])\n",
    "\n",
    "ada_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', ada_model)\n",
    "])\n",
    "\n",
    "et_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', et_model)\n",
    "])\n",
    "\n",
    "# Paso 7: Ajustar los pipelines a los datos de entrenamiento\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "ada_pipeline.fit(X_train, y_train)\n",
    "et_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Paso 8: Realizar predicciones en los datos de prueba\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "y_pred_gb = gb_pipeline.predict(X_test)\n",
    "y_pred_ada = ada_pipeline.predict(X_test)\n",
    "y_pred_et = et_pipeline.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE para Random Forest\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = math.sqrt(mse_rf)\n",
    "print(\"RMSE (Random Forest):\", rmse_rf)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE para Gradient Boosting\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "rmse_gb = math.sqrt(mse_gb)\n",
    "print(\"RMSE (Gradient Boosting):\", rmse_gb)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE para AdaBoost\n",
    "mse_ada = mean_squared_error(y_test, y_pred_ada)\n",
    "rmse_ada = math.sqrt(mse_ada)\n",
    "print(\"RMSE (AdaBoost):\", rmse_ada)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE para Extra Trees\n",
    "mse_et = mean_squared_error(y_test, y_pred_et)\n",
    "rmse_et = math.sqrt(mse_et)\n",
    "print(\"RMSE (Extra Trees):\", rmse_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;rf&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              RandomForestRegressor(max_depth=12,\n",
       "                                                                    min_samples_leaf=5,\n",
       "                                                                    min_samples_split=10))])),\n",
       "                            (&#x27;XG&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              XGBRegressor(base_score=None,\n",
       "                                                           booster=None,\n",
       "                                                           callbacks=None,\n",
       "                                                           colsample_bylevel...\n",
       "                                                           predictor=None,\n",
       "                                                           random_state=None, ...))])),\n",
       "                            (&#x27;GraBoosst&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              GradientBoostingRegressor(max_depth=5))])),\n",
       "                            (&#x27;ExtraTrees&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              ExtraTreesRegressor(min_samples_split=8,\n",
       "                                                                  n_estimators=400))]))],\n",
       "                weights=[0.15, 0.4, 0.35, 0.1])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;rf&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              RandomForestRegressor(max_depth=12,\n",
       "                                                                    min_samples_leaf=5,\n",
       "                                                                    min_samples_split=10))])),\n",
       "                            (&#x27;XG&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              XGBRegressor(base_score=None,\n",
       "                                                           booster=None,\n",
       "                                                           callbacks=None,\n",
       "                                                           colsample_bylevel...\n",
       "                                                           predictor=None,\n",
       "                                                           random_state=None, ...))])),\n",
       "                            (&#x27;GraBoosst&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              GradientBoostingRegressor(max_depth=5))])),\n",
       "                            (&#x27;ExtraTrees&#x27;,\n",
       "                             Pipeline(steps=[(&#x27;imputer&#x27;, KNNImputer()),\n",
       "                                             (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              ExtraTreesRegressor(min_samples_split=8,\n",
       "                                                                  n_estimators=400))]))],\n",
       "                weights=[0.15, 0.4, 0.35, 0.1])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=12, min_samples_leaf=5, min_samples_split=10)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XG</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.5, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GraBoosst</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=5)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ExtraTrees</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(min_samples_split=8, n_estimators=400)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('rf',\n",
       "                             Pipeline(steps=[('imputer', KNNImputer()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('model',\n",
       "                                              RandomForestRegressor(max_depth=12,\n",
       "                                                                    min_samples_leaf=5,\n",
       "                                                                    min_samples_split=10))])),\n",
       "                            ('XG',\n",
       "                             Pipeline(steps=[('imputer', KNNImputer()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('model',\n",
       "                                              XGBRegressor(base_score=None,\n",
       "                                                           booster=None,\n",
       "                                                           callbacks=None,\n",
       "                                                           colsample_bylevel...\n",
       "                                                           predictor=None,\n",
       "                                                           random_state=None, ...))])),\n",
       "                            ('GraBoosst',\n",
       "                             Pipeline(steps=[('imputer', KNNImputer()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('model',\n",
       "                                              GradientBoostingRegressor(max_depth=5))])),\n",
       "                            ('ExtraTrees',\n",
       "                             Pipeline(steps=[('imputer', KNNImputer()),\n",
       "                                             ('scaler', StandardScaler()),\n",
       "                                             ('model',\n",
       "                                              ExtraTreesRegressor(min_samples_split=8,\n",
       "                                                                  n_estimators=400))]))],\n",
       "                weights=[0.15, 0.4, 0.35, 0.1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "voting_reg1 = VotingRegressor([('rf', rf_pipeline), ('XG', xg_pipeline), ('GraBoosst', gb_pipeline), ('ExtraTrees', et_pipeline)], \n",
    "                              weights=[3/20, 8/20, 7/20, 2/20])\n",
    "voting_reg1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE):  0.0056182599219669355\n",
      "R-squared (R2) Score:  0.44689067360385704\n",
      "Root Mean Squared Error (RMSE):  0.07495505267803455\n"
     ]
    }
   ],
   "source": [
    "ensamble1=voting_reg1.predict(X_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, ensamble1)\n",
    "r2 = r2_score(y_test, ensamble1)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): \", mse)\n",
    "print(\"R-squared (R2) Score: \", r2)\n",
    "from math import sqrt\n",
    "\n",
    "#Calcular el RMSE\n",
    "\n",
    "rmse = sqrt(mse)\n",
    "print(\"Root Mean Squared Error (RMSE): \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_nuevos_datos_imputed = X_nuevos_datos_imputed.drop(columns=[\"id\"])\n",
    "\n",
    "# Realizar predicciones en la columna objetivo (y) para los datos imputados\n",
    "y_pred1 = voting_reg1.predict(X_nuevos_datos_imputed)\n",
    "\n",
    "# Combinar las predicciones con los datos originales\n",
    "nuevos_datos[\"x_e_out [-]\"] = y_pred1\n",
    "\n",
    "# Los datos ahora tienen las predicciones en la columna objetivo (y)\n",
    "\n",
    "# Guardar los datos en un archivo para la competición de Kaggle\n",
    "nuevos_datos.to_csv(\"nuevos_datos_con_predicciones2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Leer el archivo CSV\n",
    "prueba1 = pd.read_csv(\"nuevos_datos_con_predicciones2.csv\")\n",
    "\n",
    "# Mantener solo las columnas \"id\" y \"x_e_out [mm]\"\n",
    "columnas_deseadas = [\"id\", \"x_e_out [-]\"]\n",
    "prueba1 = prueba1[columnas_deseadas]\n",
    "\n",
    "# Guardar el DataFrame resultante en un nuevo archivo CSV\n",
    "prueba1.to_csv(\"nuevos_datos_con_predicciones_filtrado11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'model__max_depth': None, 'model__min_samples_split': 6, 'model__n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but KNNImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0810616503928035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Paso 5: Definir las transformaciones y el modelo\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "scaler = StandardScaler()\n",
    "et_model = ExtraTreesRegressor()\n",
    "\n",
    "# Paso 6: Crear el pipeline\n",
    "et_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', et_model)\n",
    "])\n",
    "\n",
    "# Paso 7: Definir los parámetros de búsqueda en malla\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [None, 5, 10],\n",
    "    'model__min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Paso 8: Realizar la búsqueda en malla con validación cruzada\n",
    "grid_search = GridSearchCV(et_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Paso 9: Realizar predicciones en los datos de prueba con el mejor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "# Paso 5: Definir las transformaciones y el modelo\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "scaler = StandardScaler()\n",
    "ada_model = AdaBoostRegressor()\n",
    "\n",
    "# Paso 6: Crear el pipeline\n",
    "ada_pipeline = Pipeline([\n",
    "    ('imputer', imputer),\n",
    "    ('scaler', scaler),\n",
    "    ('model', ada_model)\n",
    "])\n",
    "\n",
    "# Paso 7: Definir los parámetros de búsqueda en malla\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__learning_rate': [0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "# Paso 8: Realizar la búsqueda en malla con validación cruzada\n",
    "grid_search = GridSearchCV(ada_pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejores hiperparámetros encontrados\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "\n",
    "# Mejor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Paso 9: Realizar predicciones en los datos de prueba con el mejor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) y el RMSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
